<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <style>
        body {
            padding: 100px;
            width: 1000px;
            margin: auto;
            text-align: left;
            font-weight: 300;
            font-family: 'Open Sans', sans-serif;
            color: #121212;
        }
        h1, h2, h3, h4 {
            font-family: 'Source Sans Pro', sans-serif;
        }
        </style>
        <title>CS 184 Rasterizer</title>
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
    </head>

    <body>

        <h1 align="middle">CS 184 Final Project Proposal: Point Cloud to Mesh</h1> 
        <br />
        <h1>Members</h1>
        <p>
            <table>
                <tr>
                    <td width="80px"> Yinghao </td>
                    <td> <i> zhangyinghao@berkeley.edu </i> </td>
                </tr>
                <tr>
                    <td width="80px"> Yifan Wang </td>
                    <td> <i> wyf020803@berkeley.edu </i> </td>
                </tr>
            </table>
        </p>
        <h1>Summary</h1>
        
        <p>
            Our proposed project aims to implement the conversion from point cloud to mesh formats.
            By implementing this conversion process, we aim to enhance the flexibility and compatibility 
            of 3D object representation in various applications, enabling users to work with the format 
            that suits their needs best.
        </p>
        
        <h1>
            Problem Description
        </h1>
        <p>
            In computer graphics, a point cloud is a set of points in a 3D space, 
            while a mesh is a set of triangles. 
        </p>
        <p>
            The ability to convert between point cloud and mesh formats is essential 
            as certain applications require a specific format. 
            For example, point clouds are commonly used for capturing 3D data from real-world objects, 
            while meshes are often used for rendering and animation purposes. 
        </p>
        <p>
            Converting one format to the other requires a fundamental change in the data structure, 
            which can be complex and computationally expensive. 
            Besides, the conversion process may result in a loss of information or introduce artifacts,
            which is undesirable when we persue an equivalent conversion.
        </p>
        <p>
            To achieve this goal, we plan to implement an existing algorithm that can accurately 
            convert between point cloud and mesh formats. Specifically, we plan to implement 
            <a href="http://research.microsoft.com/en-us/um/people/hoppe/poissonrecon.pdf"> the more challenging paper</a>
            mentioned in the Final Project Idea.
        </p>
        
        <h2 align="middle">Goals and Deliverables</h2>
        <h3>Part 1: Baseline Plan</h3>
        <p>
            We plan to develop a robust and efficient algorithm for converting point cloud to mesh and 
            mesh to point cloud formats. The algorithm should be accurate and reliable. We plan to use 
            Python to implement it to fully utilize the computational resources in an easy way.
            Another goal is to reduce data loss and introduce minimal artifacts during the conversion process. 
            The converted data should maintain its original quality, including texture, curvature, 
            and features, as much as possible.
        </p>
        <p>
            At last, optimize the conversion process to improve its performance and 
            reduce computational complexity. 
            This optimization should be achieved through techniques such as 
            surface reconstruction and mesh simplification, minimizing the 
            loss of data and improving the quality of the output.
        </p>
        <p>
            To measure the performance, we will compute: Hausdorff distance between our result and the reference data,
            running time, and scalability of our algorithm by measuring its performance on datasets of varying sizes.
        </p>
        <p>
            We will document the algorithm development process, including the research, 
            implementation, optimization, and evaluation, in a report or paper. 
            The documentation will enable others to understand and replicate our work.
        </p>
        
        
        <h3>Part 2: Inspirational Plan</h3>
        <p>
            We plan to also implement:
            <ol>
                <li> The conversion from meshes to point clouds where directly using the vertices in meshes is not enough.</li>
                <li> 3D reconstruction from imagse to point clouds, using NeRF-like techniques, and then to meshes. Thus the overall pipeline is reconstruction from 2D images to 3D meshes. </li>
            </ol>
        </p>

        <h3>Schedule</h3>
        
            <ul>
               <li> Week 1: 4/2 - 4/8</li>
                <ul>
                    <li>Proposal due 4/4, starter code</li>
                </ul>
              <li>Week 2: 4/9 - 4/15</li>
              <ul><li>Outline code</li></ul>
              <li>Week 3: 4/16 - 4/22</li>
              <ul><li>Continue working on code + milestone</li></ul>
              <li>Week 4: 4/23 - 4/29</li>
              <ul><li>Milestone due 4/25 + continue working on code</li></ul>
              <li>Week 5: 4/30 - 5/6</li>
              <ul><li>Finalize code + final presentations and final deliverables due 5/4</li></ul>
              </ul>
            </ul>

        
        <h2 align="middle">Resources</h2>
        <p>
            We will implement the algorithm described in 
            <a href="http://research.microsoft.com/en-us/um/people/hoppe/poissonrecon.pdf"> the paper</a>.
            We will use <a href="http://graphics.stanford.edu/data/3Dscanrep/"> the Stanford 3D Scanning Repository</a> as 
            our dataset.
            Our advanced work needs to implement a NeRF-like algorithm, which is described in
            <a href="https://github.com/Xharlie/pointnerf"> Point-NeRF</a>.
        </p>

    </body>
</html>
